<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SuFIA">
  <meta name="keywords" content="SuFIA">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SuFIA: Language-Guided Augmented Dexterity for Robotic Surgical Assistants</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-C7DXW28295"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-C7DXW28295');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">  
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://orbit-surgical.github.io/sufia-bc/">
            SuFIA-BC
          </a>
          <a class="navbar-item" href="https://orbit-surgical.github.io/">
            ORBIT-Surgical
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">SuFIA: Language-Guided Augmented Dexterity <br> for Robotic Surgical Assistants</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://masoudmoghani.com/">Masoud Moghani</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://larsdoorenbos.github.io/">Lars Doorenbos</a><sup>2</sup>,</span>
            <span class="author-block">
              William Chung-Ho Panitch<sup>3</sup>,</span><br>
            <span class="author-block">
              <a href="https://developer.nvidia.com/blog/author/shuver/">Sean Huver</a><sup>4</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/mahdiazizian">Mahdi Azizian</a><sup>4</sup>,</span>
            <span class="author-block">
              <a href="https://goldberg.berkeley.edu/">Ken Goldberg</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://animesh.garg.tech/">Animesh Garg</a><sup>1,4,5</sup></span>
          </div>

          &nbsp;

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Toronto,</span>
            <span class="author-block"><sup>2</sup>University of Bern,</span>
            <span class="author-block"><sup>3</sup>University of California, Berkeley,</span><br>
            <span class="author-block"><sup>4</sup>NVIDIA,</span>
            <span class="author-block"><sup>5</sup>Georgia Institute of Technology</span>
          </div>

          &nbsp;

          <div class="is-size-5 publication-authors">
            <span class="author-block">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2024</span>
          </div>
 
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2405.05226"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2405.05226"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/ZfZJd4ENny8"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://orbit-surgical.github.io/sufia"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (release upon publication)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- 
              <span class="link-block">
                <a href="https://orbit-surgical.github.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img class="img-responsive img-rounded" src="./static/images/teaser.svg" alt="" width="800" >
< !--       
      <h2 class="subtitle has-text-centered">

      </h2> -- >

    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this work, we present SuFIA, the first framework for natural language-guided augmented dexterity
            for robotic surgical assistants. SuFIA incorporates the strong reasoning capabilities of
            large language models (LLMs) with perception modules to implement high-level planning and low-level control
            of a robot for surgical sub-task execution. This enables a learning-free approach to surgical augmented dexterity
            without any in-context examples or motion primitives. SuFIA uses a human-in-the-loop paradigm by restoring
            control to the surgeon in the case of insufficient information, mitigating unexpected errors for mission-critical
            tasks. We evaluate SuFIA on four surgical sub-tasks in a simulation environment and two sub-tasks on a physical
            surgical robotic platform in the lab, demonstrating its ability to perform common surgical sub-tasks through
            supervised autonomous operation under challenging physical and workspace conditions.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/ZfZJd4ENny8"></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
    
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Example Tasks. -->
    <h2 class="title is-3">Example Tasks</h2>
    <div class="content has-text-justified">
      <h2 class="title is-4">Suture Needle Handover</h2>
      <p>
        In this task, the robot hands over a suture needle from one arm to the other. SuFIA queries a language model to
        understand the surgeon's request and plan the handover motion and also communicates its intentions to the surgeon.
        SuFIA directly devises and executes the low-level robot actions and trajectories for the handover motion.
        The robot can adapt to the surgeon's preferences and adjust the handover motion accordingly.
      </p>
    </div>
    <div class="content has-text-centered">
      <video id="needle-handover" controls muted playsinline width="75%">
        <source src="./static/videos/SuFIA-NH.mp4"
                type="video/mp4">
      </video>
    </div>

    <div class="content has-text-justified">
      <h2 class="title is-4">Vessel Dilation</h2>
      <p>
        In this task, a spring clamp assembly holds a soft vessel phantom from two points.
        The dVRK arm is required to grip the vessel rim from a third point facing the robot
        and dilate the vessel by pulling backward.
      </p>
    </div>
    <div class="content has-text-centered">
      <video id="needle-handover" controls muted playsinline width="75%">
        <source src="./static/videos/SuFIA-VD.mp4"
                type="video/mp4">
      </video>
    </div>
    <!--/ Example Tasks. -->
    
    <!-- !-- Supplementary Material. --
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Supplementary Material</h2>

        <div class="content has-text-justified">
          <h2 class="title is-4">Supplementary Material</h2>
          <p>
            Supplementary Material
          </p>
        </div>
      </div>
    </div>
    !--/ Supplementary Material. -- -->

        <!-- Related Projects. -->
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">Our Related Projects</h2>
    
            <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr style="padding:0px">
                <td style="padding:0px">
                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    
                    <tr onmouseout="sufia_bc_stop()" onmouseover="sufia_bc_start()">
                      <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                          <div class="two" id='sufia_bc_video'><video  width=100% muted autoplay loop>
                          <source src="static/videos/tissue.mp4" type="video/mp4">
                          Your browser does not support the video tag.
                          </video></div>
                          <img src='static/images/Organs.jpg' width="100%" id='sufia_bc_image'>
                        </div>
                        <script type="text/javascript">
                          function sufia_bc_start() {
                            document.getElementById('sufia_bc_video').style.opacity = "1";
                            document.getElementById('sufia_bc_image').style.opacity = "0";
                          }
              
                          function sufia_bc_stop() {
                            document.getElementById('sufia_bc_video').style.opacity = "0";
                            document.getElementById('sufia_bc_image').style.opacity = "1";
                          }
                          sufia_bc_stop()
                        </script>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="https://orbit-surgical.github.io/sufia-bc/">
                          <span>SuFIA-BC: Generating High Quality Demonstration Data for Visuomotor Policy Learning in Surgical Subtasks</span>
                        </a>
                        <br>
                        Masoud Moghani,
                        Nigel Nelson,
                        Mohamed Ghanem,
                        Andres Diaz-Pinto,<br>
                        Kush Hari,
                        Mahdi Azizian,
                        Ken Goldberg,
                        Sean Huver,
                        Animesh Garg
                        <br>
                        <a href="https://orbit-surgical.github.io/sufia-bc/">website</a>
                        /
                        <a href="https://youtu.be/jCvZYf0saRo">video</a>
                        <p></p>
                        <div class="content has-text-justified">
                        <p>
                          We present SuFIA-BC: exploring visual Behavior Cloning policies for Surgical First
                          Interactive Autonomy Assistants. We provide an enhanced surgical digital twin with
                          photorealistic human anatomical organs, integrated into ORBIT-Surgical designed to
                          generate high-quality synthetic data for solving fundamental tasks in surgical autonomy.
                          We investigate visual observation spaces including multi-view cameras and 3D visual
                          representations extracted from a single endoscopic camera view.
                        </p>
                        </div>
                      </td>
                    </tr>              
                  </tbody></table>
                </td>
              </tr>
            </table>
    
          </div>
        </div>
        <!--/ Related Projects. -->


  </div>
</section>



<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="mailto:moghani@cs.toronto.edu">
        <i class="fa fa-envelope"></i>
      </a>
      <a class="icon-link"
         href="https://arxiv.org/pdf/2405.05226">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://orbit-surgical.github.io/sufia" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The template of this website is borrowed from the source code of <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. The template is licensed under a <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            <!-- Please remember to remove the analytics code included in the header of the website which
            you do not want on your website. -->
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
